import os
from openai import OpenAI
from dotenv import load_dotenv

from agents.head_agent import run_head_agent  # âœ… Now active

load_dotenv() 

def test_openai_api(user_query: str, client: OpenAI, model: str) -> str:
    """
    You are a helpful AI assistant. Answer the user query in a polite and respectful way.
    """
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": user_query}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ Error while calling OpenAI API: {e}"


def main():
    print("ğŸ§  Welcome to WiseStreet - Your AI Investment Research Assistant\n")

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ Please set the OPENAI_API_KEY environment variable.")
        return

    model = os.getenv("OPENAI_MODEL")  # Default to gpt-4o if not set
    client = OpenAI(api_key=api_key)

    while True:
        try:
            user_query = input("ğŸ§¾ Ask a financial question (or type 'exit' to quit):\n> ")
            if user_query.lower() in ["exit", "quit"]:
                print("ğŸ‘‹ Exiting WiseStreet. See you soon.")
                break

            print("\nğŸ’¡ Thinking...\n")
            # ğŸ” Core workflow - uses macro agent for now
            answer = run_head_agent(user_query, client, model)
            # For test purposes only:
            # answer = test_openai_api(user_query, client, model)

            print(f"\nâœ… Answer:\n{answer}\n")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Exiting WiseStreet. Goodbye!")
            break
        except Exception as e:
            print(f"âš ï¸ Error: {e}\n")

if __name__ == "__main__":
    main()
